# Geometry-Consistent Video Diffusion for Robotic Visual Policy Transfer

This repository contains the anonymous project page for the paper submission.

## Project Overview

This project presents a diffusion-based video generation framework for robotic data synthesis. The framework integrates multi-view geometry with explicit, fine-grained control over scene components, including background textures and object-level attributes.

## Features

- **Multi-view Geometry Consistency**: Ensures geometric consistency across views through cross-view feature interaction and global depth-normal priors
- **Fine-grained Control**: Supports background replacement and object swapping for diverse video synthesis
- **Real2Real Transfer**: Enables flexible editing of background and foreground attributes
- **Sim2Real Transfer**: Generates photorealistic videos from simulated structural inputs

## Project Page

The project page is available at `index.html`. Open it in a web browser to view the full content.

## Note

This is an anonymous version prepared for conference submission. All author and affiliation information has been removed.
